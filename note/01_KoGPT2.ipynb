{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1c85a4-e969-4f86-bdc8-84ac3f956cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7143a6-ba4d-48b6-b8e0-ca0dec88f4c6",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pdm add -dG note ipywidgets\n",
    "```\n",
    "\n",
    "```\n",
    "/home/tom/code/king-kogpt2/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "  from .autonotebook import tqdm as notebook_tqdm\n",
    "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1e43f",
   "metadata": {},
   "source": [
    "```\n",
    "$ nvidia-smi\n",
    "Tue Jun 24 14:27:14 2025       \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 565.72                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
    "|-----------------------------------------+------------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                        |               MIG M. |\n",
    "|=========================================+========================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0  On |                  N/A |\n",
    "| N/A   44C    P8              2W /   85W |     241MiB /   8188MiB |      0%      Default |\n",
    "|                                         |                        |                  N/A |\n",
    "+-----------------------------------------+------------------------+----------------------+\n",
    "                                                                                         \n",
    "+-----------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                              |\n",
    "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
    "|        ID   ID                                                               Usage      |\n",
    "|=========================================================================================|\n",
    "|    0   N/A  N/A       169      C   /ollama                                     N/A      |\n",
    "+-----------------------------------------------------------------------------------------+\n",
    "\n",
    "$ PIP_EXTRA_INDEX_URL=https://download.pytorch.org/whl/cu118 pdm add torch torchvision torchaudio\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59a592e-785a-4743-8476-c4fd30f73b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6b5fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['â–ì•ˆë…•',\n",
       " 'í•˜',\n",
       " 'ì„¸',\n",
       " 'ìš”.',\n",
       " 'â–í•œêµ­ì–´',\n",
       " 'â–G',\n",
       " 'P',\n",
       " 'T',\n",
       " '-2',\n",
       " 'â–ì…',\n",
       " 'ë‹ˆë‹¤.',\n",
       " 'ğŸ˜¤',\n",
       " ':)',\n",
       " 'l^o']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721d00a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797bd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059fc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0389dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ê·¼ìœ¡ì´ ì»¤ì§€ê¸° ìœ„í•´ì„œëŠ”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4942cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbecbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ids = model.generate(input_ids,\n",
    "                           max_length=128,\n",
    "                           repetition_penalty=2.0,\n",
    "                           pad_token_id=tokenizer.pad_token_id,\n",
    "                           eos_token_id=tokenizer.eos_token_id,\n",
    "                           bos_token_id=tokenizer.bos_token_id,\n",
    "                           use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42dc0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = tokenizer.decode(gen_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e8cc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¼ìœ¡ì´ ì»¤ì§€ê¸° ìœ„í•´ì„œëŠ” ë¬´ì—‡ë³´ë‹¤ ê·œì¹™ì ì¸ ìƒí™œìŠµê´€ì´ ì¤‘ìš”í•˜ë‹¤.\n",
      "íŠ¹íˆ, ì•„ì¹¨ì‹ì‚¬ëŠ” ë‹¨ë°±ì§ˆê³¼ ë¹„íƒ€ë¯¼ì´ í’ë¶€í•œ ê³¼ì¼ê³¼ ì±„ì†Œë¥¼ ë§ì´ ì„­ì·¨í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.\n",
      "ë˜í•œ í•˜ë£¨ 30ë¶„ ì´ìƒ ì¶©ë¶„í•œ ìˆ˜ë©´ì„ ì·¨í•˜ëŠ” ê²ƒë„ ë„ì›€ì´ ëœë‹¤.\n",
      "ì•„ì¹¨ ì‹ì‚¬ë¥¼ ê±°ë¥´ì§€ ì•Šê³  ê·œì¹™ì ìœ¼ë¡œ ìš´ë™ì„ í•˜ë©´ í˜ˆì•¡ìˆœí™˜ì— ë„ì›€ì„ ì¤„ ë¿ë§Œ ì•„ë‹ˆë¼ ì‹ ì§„ëŒ€ì‚¬ë¥¼ ì´‰ì§„í•´ ì²´ë‚´ ë…¸íë¬¼ì„ ë°°ì¶œí•˜ê³  í˜ˆì••ì„ ë‚®ì¶°ì¤€ë‹¤.\n",
      "ìš´ë™ì€ í•˜ë£¨ì— 10ë¶„ ì •ë„ë§Œ í•˜ëŠ” ê²Œ ì¢‹ìœ¼ë©° ìš´ë™ í›„ì—ëŠ” ë°˜ë“œì‹œ ìŠ¤íŠ¸ë ˆì¹­ì„ í†µí•´ ê·¼ìœ¡ëŸ‰ì„ ëŠ˜ë¦¬ê³  ìœ ì—°ì„±ì„ ë†’ì—¬ì•¼ í•œë‹¤.\n",
      "ìš´ë™ í›„ ë°”ë¡œ ì ìë¦¬ì— ë“œëŠ” ê²ƒì€ í”¼í•´ì•¼ í•˜ë©° íŠ¹íˆ ì•„ì¹¨ì— ì¼ì–´ë‚˜ë©´ ëª¸ì´ í”¼ê³¤í•´ì§€ê¸° ë•Œë¬¸ì— ë¬´ë¦¬í•˜ê²Œ ì›€ì§ì´ë©´ ì˜¤íˆë ¤ ì—­íš¨ê³¼ê°€ ë‚  ìˆ˜ë„ ìˆë‹¤.\n",
      "ìš´ë™ì„\n"
     ]
    }
   ],
   "source": [
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb719b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
